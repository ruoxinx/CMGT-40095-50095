{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardhat Detection in Construction: Deep Learning Tutorial Using Google Drive\n",
    "\n",
    "Author: *Your Name*  \n",
    "Date: *Today's Date*\n",
    "\n",
    "## Overview\n",
    "In this notebook, you will:\n",
    "1. Mount your Google Drive to access a large Hardhat Detection dataset.\n",
    "2. Split the raw dataset (which lacks predefined splits) into training, validation, and testing sets.\n",
    "3. Set up and train YOLOv5 for hardhat detection while monitoring training metrics.\n",
    "4. Evaluate the trained model on the test set.\n",
    "\n",
    "> **Note:** This notebook is for Google Colab with GPU enabled. Ensure your dataset is stored in your Drive (or shared Drive) and update the path accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mounting Google Drive\n",
    "\n",
    "We will mount Google Drive to access the dataset. The dataset should be stored in your Drive under a folder (for example, `Hardhat_Dataset_Raw`)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"Google Drive mounted. Your files are accessible under '/content/drive/My Drive/'.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting the Dataset Directory and Inspecting Data\n",
    "\n",
    "Assume the raw dataset is stored in your Drive under the folder:\n",
    "\n",
    "`/content/drive/My Drive/Hardhat_Dataset_Raw/`\n",
    "\n",
    "This folder should have the following structure:\n",
    "\n",
    "```\n",
    "Hardhat_Dataset_Raw/\n",
    "   ├── images/        # all raw images\n",
    "   └── annotations/   # all raw annotation files in YOLO format\n",
    "```\n",
    "\n",
    "Let's set the path and verify the number of images."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, glob\n",
    "\n",
    "# Set the path to your raw dataset on Google Drive\n",
    "raw_dataset_dir = '/content/drive/My Drive/Hardhat_Dataset_Raw'\n",
    "raw_images_dir = os.path.join(raw_dataset_dir, 'images')\n",
    "\n",
    "all_images = glob.glob(os.path.join(raw_images_dir, '*.jpg'))\n",
    "print(\"Total raw images found:\", len(all_images))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Splitting the Dataset into Train, Validation, and Test\n",
    "\n",
    "Since the raw dataset lacks splits, we will create three new folders within a new folder (e.g., `Hardhat_Dataset_Split`) in your Drive. The split ratios will be:\n",
    "\n",
    "- **Train:** 80%\n",
    "- **Validation:** 10%\n",
    "- **Test:** 10%\n",
    "\n",
    "The folder structure will be:\n",
    "\n",
    "```\n",
    "Hardhat_Dataset_Split/\n",
    "   ├── train/\n",
    "   │    ├── images/\n",
    "   │    └── annotations/\n",
    "   ├── val/\n",
    "   │    ├── images/\n",
    "   │    └── annotations/\n",
    "   └── test/\n",
    "        ├── images/\n",
    "        └── annotations/\n",
    "```\n",
    "\n",
    "Let's run a script to perform the split."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shutil, random\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Define the destination split directory\n",
    "split_dir = '/content/drive/My Drive/Hardhat_Dataset_Split'\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    os.makedirs(os.path.join(split_dir, split, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split_dir, split, 'annotations'), exist_ok=True)\n",
    "\n",
    "# Get list of all image filenames (assume .jpg extension)\n",
    "all_image_files = [f for f in os.listdir(raw_images_dir) if f.endswith('.jpg')]\n",
    "total_images = len(all_image_files)\n",
    "print(f\"Total images to split: {total_images}\")\n",
    "\n",
    "random.shuffle(all_image_files)\n",
    "\n",
    "train_end = int(0.8 * total_images)\n",
    "val_end = int(0.9 * total_images)\n",
    "\n",
    "train_files = all_image_files[:train_end]\n",
    "val_files = all_image_files[train_end:val_end]\n",
    "test_files = all_image_files[val_end:]\n",
    "\n",
    "print(f\"Train: {len(train_files)}, Validation: {len(val_files)}, Test: {len(test_files)}\")\n",
    "\n",
    "def copy_files(file_list, src_img_dir, src_ann_dir, dest_split):\n",
    "    dest_img_dir = os.path.join(split_dir, dest_split, 'images')\n",
    "    dest_ann_dir = os.path.join(split_dir, dest_split, 'annotations')\n",
    "    for fname in file_list:\n",
    "        shutil.copy(os.path.join(src_img_dir, fname), dest_img_dir)\n",
    "        ann_fname = os.path.splitext(fname)[0] + '.txt'\n",
    "        src_ann_file = os.path.join(src_ann_dir, ann_fname)\n",
    "        if os.path.exists(src_ann_file):\n",
    "            shutil.copy(src_ann_file, dest_ann_dir)\n",
    "\n",
    "copy_files(train_files, os.path.join(raw_dataset_dir, 'images'), os.path.join(raw_dataset_dir, 'annotations'), 'train')\n",
    "copy_files(val_files, os.path.join(raw_dataset_dir, 'images'), os.path.join(raw_dataset_dir, 'annotations'), 'val')\n",
    "copy_files(test_files, os.path.join(raw_dataset_dir, 'images'), os.path.join(raw_dataset_dir, 'annotations'), 'test')\n",
    "\n",
    "print(\"Dataset successfully split into train, val, and test sets.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. YOLOv5 Dataset Configuration\n",
    "\n",
    "Create a YOLOv5 configuration file (e.g., `hardhat.yaml`) that points to the training and validation sets. For example:\n",
    "\n",
    "```\n",
    "train: Hardhat_Dataset_Split/train/images\n",
    "val: Hardhat_Dataset_Split/val/images\n",
    "names: [\"helmet\", \"head\"]\n",
    "nc: 2\n",
    "```\n",
    "\n",
    "We'll create this file using Python."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import yaml\n",
    "\n",
    "config_data = {\n",
    "    'train': os.path.join(split_dir, 'train', 'images'),\n",
    "    'val': os.path.join(split_dir, 'val', 'images'),\n",
    "    'names': ['helmet', 'head'],\n",
    "    'nc': 2\n",
    "}\n",
    "\n",
    "with open('hardhat.yaml', 'w') as f:\n",
    "    yaml.dump(config_data, f)\n",
    "\n",
    "print(\"Created YOLOv5 dataset configuration file: hardhat.yaml\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setting Up YOLOv5 Environment\n",
    "\n",
    "If you haven't already, clone the YOLOv5 repository and install dependencies. (This step assumes you are running in Colab.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(\"Running in Colab?\", IN_COLAB)\n",
    "\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/ultralytics/yolov5.git\n",
    "    %cd yolov5\n",
    "    !pip install -r requirements.txt\n",
    "else:\n",
    "    print(\"Ensure YOLOv5 is installed locally.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training YOLOv5 on the Dataset\n",
    "\n",
    "Now that the dataset is split and the configuration file is created, we can start training the YOLOv5 model. We'll use the pretrained YOLOv5s model and fine-tune it for 10 epochs (adjust epochs and batch size as needed).\n",
    "\n",
    "Run the training command from within the YOLOv5 directory:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if IN_COLAB:\n",
    "    %cd /content/yolov5\n",
    "    !python train.py --img 640 --batch 16 --epochs 10 --data ../hardhat.yaml --weights yolov5s.pt --name hardhat_exp_large\n",
    "else:\n",
    "    print(\"Run the training command in your local YOLOv5 setup.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Monitoring Training\n",
    "\n",
    "During training, YOLOv5 displays training and validation loss, mAP, and other metrics. You can monitor these metrics via the console output and later by reviewing the `results.png` image in the experiment folder (e.g., `runs/train/hardhat_exp_large/results.png`)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# (Optional) Display training results image if available\n",
    "from IPython.display import Image, display\n",
    "exp_path = '/content/yolov5/runs/train/hardhat_exp_large'\n",
    "results_img = os.path.join(exp_path, 'results.png')\n",
    "if os.path.exists(results_img):\n",
    "    display(Image(filename=results_img))\n",
    "else:\n",
    "    print(\"Training results image not found. Check the experiment folder.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Testing & Inference\n",
    "\n",
    "After training, use the best model weights (e.g., `best.pt`) to run inference on the test set. This step will generate predictions (bounding boxes) on the unseen test images."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if IN_COLAB:\n",
    "    %cd /content/yolov5\n",
    "    !python detect.py --weights runs/train/hardhat_exp_large/weights/best.pt --img 640 --conf 0.25 --source ../Hardhat_Dataset_Split/test/images --name hardhat_test_inference\n",
    "else:\n",
    "    print(\"Run the detection command in your local environment.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizing Inference Results\n",
    "\n",
    "After running inference, inspect the folder `runs/detect/hardhat_test_inference` for images with predicted bounding boxes. You can display a sample result image below:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result_img = '/content/yolov5/runs/detect/hardhat_test_inference/exp/image_001.jpg'\n",
    "if os.path.exists(result_img):\n",
    "    display(Image(filename=result_img))\n",
    "else:\n",
    "    print(\"Result image not found. Check your detection output folder.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Tips for Improvement & Next Steps\n",
    "\n",
    "1. **Data Augmentation**: Use Albumentations to add more diversity (flips, rotations, color jitter).\n",
    "2. **Longer Training**: Increase epochs or batch size if GPU resources allow.\n",
    "3. **Hyperparameter Tuning**: Experiment with different learning rates and YOLOv5 settings.\n",
    "4. **Model Evaluation**: Monitor metrics such as mAP, precision, and recall to gauge model performance.\n",
    "5. **Real-World Deployment**: Consider integrating the trained model with live camera feeds for on-site safety monitoring.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion & Next Steps\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "1. Use Google Drive to access a large Hardhat Detection dataset.\n",
    "2. Split the dataset into training, validation, and testing sets.\n",
    "3. Configure YOLOv5 for training with the prepared dataset.\n",
    "4. Train the model while monitoring training metrics.\n",
    "5. Run inference on unseen test images and visualize the predictions.\n",
    "\n",
    "Deep learning methods like YOLOv5 can significantly enhance safety monitoring on construction sites. Keep experimenting with data augmentation, hyperparameter tuning, and longer training to improve your model's performance.\n",
    "\n",
    "Happy Coding and Stay Safe on Site!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Resources & References\n",
    "1. [YOLOv5 GitHub](https://github.com/ultralytics/yolov5)\n",
    "2. [Hardhat Detection Dataset on GitHub](<YOUR_GITHUB_REPO_URL>)\n",
    "3. [Ultralytics YOLOv5 Documentation](https://docs.ultralytics.com/)\n",
    "4. [Albumentations Library](https://github.com/albumentations-team/albumentations)\n",
    "\n",
    "Feel free to modify paths, hyperparameters, and configurations as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
