{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardhat Detection in Construction: Deep Learning Tutorial Using Google Drive\n",
    "\n",
    "Author: *[Your Name]*  \n",
    "Date: *[Today's Date]*\n",
    "\n",
    "## Overview\n",
    "In this notebook, you will:\n",
    "1. Mount your Google Drive and download the Hardhat Detection dataset from a shared Google Drive link using `gdown`.\n",
    "2. Unzip and split the dataset into training, validation, and testing sets.\n",
    "3. Set up YOLOv5 for object detection, configure the dataset, and start training with monitoring.\n",
    "4. Evaluate and test the model using inference on unseen images.\n",
    "\n",
    "> **Note:** This notebook is designed for Google Colab with GPU enabled. Update the Google Drive file ID in the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mounting Google Drive & Downloading the Dataset\n",
    "\n",
    "We use `gdown` to download the zipped dataset from a shared Google Drive link. Replace `<YOUR_GOOGLE_DRIVE_FILE_ID>` with your file's ID. The expected folder structure after unzipping is:\n",
    "\n",
    "```\n",
    "HardHat_Dataset/\n",
    "   ├── images/\n",
    "   │    ├── image_0001.jpg\n",
    "   │    ├── ...\n",
    "   └── annotations/\n",
    "        ├── image_0001.txt\n",
    "        ├── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"Google Drive mounted.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install gdown if not already installed\n",
    "!pip install gdown"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Dataset from Google Drive\n",
    "Replace `<YOUR_GOOGLE_DRIVE_FILE_ID>` with your shared file ID. This file should be a zip archive of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import gdown\n",
    "\n",
    "# Replace with your file ID from the shared Google Drive link\n",
    "file_id = '<YOUR_GOOGLE_DRIVE_FILE_ID>'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "output = '/content/hardhat_dataset.zip'\n",
    "\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "# Unzip the dataset\n",
    "!unzip -q /content/hardhat_dataset.zip -d /content/HardHat_Dataset\n",
    "print(\"Dataset downloaded and unzipped to /content/HardHat_Dataset\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting the Dataset into Train, Validation, and Test Sets\n",
    "\n",
    "Since the raw dataset has no predefined splits, we will create training (80%), validation (10%), and test (10%) subsets. This will create the following folder structure:\n",
    "\n",
    "```\n",
    "HardHat_Dataset/\n",
    "   ├── images/\n",
    "   ├── annotations/\n",
    "   ├── train/ (new folder)\n",
    "   │    ├── images/\n",
    "   │    └── annotations/\n",
    "   ├── val/ (new folder)\n",
    "   │    ├── images/\n",
    "   │    └── annotations/\n",
    "   └── test/ (new folder)\n",
    "        ├── images/\n",
    "        └── annotations/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, shutil, random\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Define the original dataset directories\n",
    "base_dir = '/content/HardHat_Dataset'\n",
    "orig_images_dir = os.path.join(base_dir, 'images')\n",
    "orig_ann_dir = os.path.join(base_dir, 'annotations')\n",
    "\n",
    "# Create new split directories\n",
    "splits = ['train', 'val', 'test']\n",
    "for split in splits:\n",
    "    os.makedirs(os.path.join(base_dir, split, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(base_dir, split, 'annotations'), exist_ok=True)\n",
    "\n",
    "# Get list of all image files\n",
    "all_images = [f for f in os.listdir(orig_images_dir) if f.endswith('.jpg')]\n",
    "total_images = len(all_images)\n",
    "print(f\"Total images found: {total_images}\")\n",
    "\n",
    "# Shuffle and split into 80/10/10\n",
    "random.shuffle(all_images)\n",
    "train_end = int(0.8 * total_images)\n",
    "val_end = int(0.9 * total_images)\n",
    "\n",
    "train_imgs = all_images[:train_end]\n",
    "val_imgs = all_images[train_end:val_end]\n",
    "test_imgs = all_images[val_end:]\n",
    "\n",
    "print(f\"Train: {len(train_imgs)}, Validation: {len(val_imgs)}, Test: {len(test_imgs)}\")\n",
    "\n",
    "def copy_files(file_list, src_images, src_ann, dest_split):\n",
    "    dest_img = os.path.join(base_dir, dest_split, 'images')\n",
    "    dest_ann = os.path.join(base_dir, dest_split, 'annotations')\n",
    "    for fname in file_list:\n",
    "        shutil.copy(os.path.join(src_images, fname), dest_img)\n",
    "        ann_fname = os.path.splitext(fname)[0] + '.txt'\n",
    "        src_ann_file = os.path.join(src_ann, ann_fname)\n",
    "        if os.path.exists(src_ann_file):\n",
    "            shutil.copy(src_ann_file, dest_ann)\n",
    "\n",
    "copy_files(train_imgs, orig_images_dir, orig_ann_dir, 'train')\n",
    "copy_files(val_imgs, orig_images_dir, orig_ann_dir, 'val')\n",
    "copy_files(test_imgs, orig_images_dir, orig_ann_dir, 'test')\n",
    "\n",
    "print(\"Dataset split into train, validation, and test sets.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. YOLOv5 Dataset Configuration\n",
    "\n",
    "Create a YAML configuration file (named `hardhat.yaml`) for YOLOv5. It should point to the train and validation image directories and list the class names."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import yaml\n",
    "\n",
    "config_data = {\n",
    "    'train': os.path.join(base_dir, 'train', 'images'),\n",
    "    'val': os.path.join(base_dir, 'val', 'images'),\n",
    "    'names': ['helmet', 'head'],\n",
    "    'nc': 2\n",
    "}\n",
    "\n",
    "with open('hardhat.yaml', 'w') as f:\n",
    "    yaml.dump(config_data, f)\n",
    "\n",
    "print(\"Created YOLOv5 dataset configuration file: hardhat.yaml\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setting Up YOLOv5 Environment\n",
    "\n",
    "If you haven't already cloned YOLOv5, do so now. This code is intended to run in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(\"Running in Colab?\", IN_COLAB)\n",
    "\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/ultralytics/yolov5.git\n",
    "    %cd yolov5\n",
    "    !pip install -r requirements.txt\n",
    "else:\n",
    "    print(\"Ensure YOLOv5 is installed locally.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training YOLOv5 on the Dataset\n",
    "\n",
    "Now that the dataset is split and the configuration file is ready, we can start training.\n",
    "\n",
    "This example uses the pretrained YOLOv5s model and fine-tunes it for 10 epochs. You can monitor training progress (loss, mAP, etc.) via the training logs and by checking the generated `results.png` in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if IN_COLAB:\n",
    "    %cd /content/yolov5\n",
    "    !python train.py --img 640 --batch 16 --epochs 10 --data ../hardhat.yaml --weights yolov5s.pt --name yolo_hardhat_exp\n",
    "else:\n",
    "    print(\"Run the YOLOv5 training command in your local environment.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monitoring Training & Model Testing\n",
    "\n",
    "During training, YOLOv5 outputs logs that include training/validation loss and mAP metrics. After training, review the `runs/train/yolo_hardhat_exp/results.png` plot to check the performance curves.\n",
    "\n",
    "After training, test the model on the test set. Use the following command to run inference on test images."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if IN_COLAB:\n",
    "    %cd /content/yolov5\n",
    "    !python detect.py --weights runs/train/yolo_hardhat_exp/weights/best.pt --img 640 --conf 0.25 --source ../HardHat_Dataset/test/images --name test_inference\n",
    "else:\n",
    "    print(\"Run the detection command in your local environment.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing Inference Results\n",
    "\n",
    "After running inference, check the folder `runs/detect/test_inference` for images with predicted bounding boxes. Display a sample result image below:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Set path to a sample result image (adjust filename if necessary)\n",
    "result_img = '/content/yolov5/runs/detect/test_inference/exp/image_001.jpg'\n",
    "if os.path.exists(result_img):\n",
    "    display(Image(filename=result_img))\n",
    "else:\n",
    "    print(\"Result image not found. Check your detection output folder.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tips for Improvement & Next Steps\n",
    "\n",
    "1. **Data Augmentation**: Increase training diversity with flips, rotations, or color jitter using libraries like Albumentations.\n",
    "2. **Longer Training**: Increase epochs if you have sufficient GPU resources.\n",
    "3. **Hyperparameter Tuning**: Experiment with batch size, learning rate, and other YOLOv5 hyperparameters.\n",
    "4. **Real-World Deployment**: Explore integrating your model with live camera feeds for real-time safety monitoring on construction sites.\n",
    "5. **Model Evaluation**: Continuously monitor metrics such as mAP, precision, and recall to improve model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion & Next Steps\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "1. Download a Hardhat Detection dataset from a shared Google Drive link using `gdown`.\n",
    "2. Split the dataset into training, validation, and testing sets.\n",
    "3. Configure YOLOv5 and start training with monitoring.\n",
    "4. Run inference and test the model on unseen data.\n",
    "\n",
    "Deep learning methods like YOLOv5 can greatly enhance safety monitoring on construction sites. Continue experimenting with data augmentation, hyperparameter tuning, and integration with real-time systems.\n",
    "\n",
    "Happy Coding and Stay Safe on Site!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Resources & References\n",
    "1. [YOLOv5 GitHub](https://github.com/ultralytics/yolov5)\n",
    "2. [Hardhat Detection Dataset on GitHub](<YOUR_GITHUB_REPO_URL>)\n",
    "3. [Ultralytics YOLOv5 Documentation](https://docs.ultralytics.com/)\n",
    "4. [Albumentations Library](https://github.com/albumentations-team/albumentations)\n",
    "\n",
    "Feel free to modify paths, hyperparameters, or configurations as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
