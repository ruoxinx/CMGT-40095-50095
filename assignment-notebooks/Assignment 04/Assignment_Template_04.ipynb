{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment: Building Permit Analysis & ML in Construction**\n",
    "\n",
    "#### *Student Name:*  \n",
    "#### *Date:*  \n",
    "\n",
    "Welcome to the assignment notebook! Follow the instructions below to complete all tasks. Use additional code and markdown cells as needed. Make sure to document your decisions and findings.\n",
    "\n",
    "---\n",
    "## **1. Data Loading & Initial Exploration**\n",
    "1. Download the dataset (e.g., Seattle Building Permits) from Kaggle.\n",
    "2. Load it here, handle any immediate file path issues.\n",
    "3. Print dataset shape, columns, and first few rows.\n",
    "\n",
    "> **Hint**: If the dataset is large, consider sampling or filtering to a certain time period to keep the notebook manageable.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. Data Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Example: load data\n",
    "# df = pd.read_csv('path_to_your_building_permits.csv')\n",
    "# print(df.shape)\n",
    "# df.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Data Cleaning & Preprocessing**\n",
    "Here, you'll:\n",
    "1. Inspect missing values and decide how to handle them.\n",
    "2. Check for duplicates or incorrect data.\n",
    "3. Potentially create new columns (feature engineering)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning\n",
    "# Example steps:\n",
    "# print(df.isna().sum())\n",
    "# df.dropna(subset=['SomeImportantColumn'], inplace=True)\n",
    "# df['NewFeature'] = df['ColumnA'] / df['ColumnB']\n",
    "# df.drop_duplicates(inplace=True)\n",
    "# etc.\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Exploratory Data Analysis (EDA)**\n",
    "Create plots (histograms, bar charts, correlation heatmap, etc.) to understand distributions and relationships. Summarize interesting insights."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis\n",
    "# Example EDA code:\n",
    "# df.hist(figsize=(12,8))\n",
    "# plt.show()\n",
    "\n",
    "# sns.countplot(x='PermitClass', data=df)\n",
    "# plt.show()\n",
    "\n",
    "# # Correlation heatmap:\n",
    "# corr = df.corr(numeric_only=True)\n",
    "# sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "# plt.show()\n",
    "\n",
    "# # Summaries:\n",
    "# print(df.describe())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Choose a Target & Split Data**\n",
    "- Decide whether you are predicting a numeric target (regression) or a categorical target (classification).\n",
    "- Perform a train/test split.\n",
    "- Watch out for data leakage (e.g., no usage of future columns, date of completion, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 4. Choose target column\n",
    "# Example: If predicting ProjectValue (regression)\n",
    "# or PermitStatus (classification)\n",
    "# X = df.drop('TargetColumn', axis=1)\n",
    "# y = df['TargetColumn']\n",
    "\n",
    "# # Train/test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                    test_size=0.2,\n",
    "#                                                    random_state=42)\n",
    "# X_train.shape, X_test.shape"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Build & Evaluate Models**\n",
    "1. Start with a **baseline model** (e.g., Linear Regression, Logistic Regression).\n",
    "2. Move on to an **advanced model** (e.g., Random Forest, XGBoost).\n",
    "3. Evaluate using **appropriate metrics** (MAE, RMSE, RÂ² for regression; accuracy, precision, recall, F1 for classification)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 5. Model Training & Evaluation Example\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Evaluate (for regression)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# print(\"MAE:\", mae)\n",
    "# print(\"RMSE:\", rmse)\n",
    "# print(\"R^2 :\", r2)\n",
    "\n",
    "# # Evaluate (for classification)\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(classification_report(y_test, y_pred))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Advanced ML & Hyperparameter Tuning (Optional)**\n",
    "Try **Random Forest**, **XGBoost**, or any other ensemble methods. Experiment with `GridSearchCV` or `RandomizedSearchCV` to find optimal parameters.\n",
    "\n",
    "Document your parameter choices and final model results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example Random Forest for regression\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# rf = RandomForestRegressor(random_state=42)\n",
    "# rf.fit(X_train, y_train)\n",
    "# y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# # Evaluate\n",
    "# mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "# print(\"RF MAE:\", mae_rf)\n",
    "\n",
    "# # Tuning example\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {\n",
    "#    'n_estimators': [50, 100],\n",
    "#    'max_depth': [None, 10, 20]\n",
    "# }\n",
    "# grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_rf = grid_search.best_estimator_\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Results & Discussion**\n",
    "- Summarize key findings.\n",
    "- Compare baseline vs. advanced model performance.\n",
    "- Reflect on data leakage precautions.\n",
    "- Make domain-specific suggestions if relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Summarize your final metrics here\n",
    "# Example:\n",
    "# print(\"Model Summary:\")\n",
    "# print(\"Baseline LR - MAE, RMSE, R^2:\", mae, rmse, r2)\n",
    "# print(\"Advanced Model (RF) - MAE, RMSE, R^2:\", mae_rf, rmse_rf, r2_rf)\n",
    "# # etc."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **End of Notebook**\n",
    "Ensure you export/save this notebook (`.ipynb`) as part of your submission.\n",
    "You can now write a short write-up or use the accompanying Word template to formally present your results and reflections.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
